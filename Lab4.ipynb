{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Weber Souza</font>\n",
    "# <font color='blue'>Deep Learning Para Aplicações de IA com PyTorch e Lightning</font>\n",
    "\n",
    "## <font color='blue'>Lab 4</font>\n",
    "## <font color='blue'>Detecção de Câncer em Imagens com Deep Learning</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DSA](imagens/Lab4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando e Carregando os Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# !pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "#!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch==2.2.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Manipulação de dados e imagens\n",
    "import os                             # Manipulacao Sistema\n",
    "import cv2                            # Open CV  \n",
    "import itertools                      # Interacao com todas imagens no disco\n",
    "import matplotlib.pyplot as plt       # Diagrama/Grafico\n",
    "import numpy as np                \n",
    "import pandas as pd\n",
    "from tqdm import tqdm                 # Permite criar uma barra de progressao\n",
    "from glob import glob                 # Manipulacao imagens\n",
    "from PIL import Image                 # ||\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')     # ignorar qualquer aviso\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn, optim                            # Neural Network , Otimizador\n",
    "from torch.autograd import Variable                    # Gradientes\n",
    "from torch.utils.data import DataLoader, Dataset       # DataLoader\n",
    "from torchvision import models, transforms             # Transformacao\n",
    "\n",
    "# Scikit-learn - Machine Learning for Python\n",
    "from sklearn.model_selection import train_test_split   # Dividir em treino e teste\n",
    "from sklearn.metrics import confusion_matrix           # Avaliacao\n",
    "from sklearn.metrics import classification_report      # Avaliacao\n",
    "\n",
    "# Pacotes para o relatório de hardware\n",
    "import gc                              \n",
    "import types\n",
    "import pkg_resources\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Seed para reproduzir os mesmos resultados\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Weber Souza\n",
      "\n",
      "PIL              : 10.2.0\n",
      "pytorch_lightning: 2.2.1\n",
      "matplotlib       : 3.8.0\n",
      "numpy            : 1.26.4\n",
      "pandas           : 2.1.4\n",
      "torch            : 2.2.1+cpu\n",
      "cv2              : 4.9.0\n",
      "torchvision      : 0.17.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Weber Souza\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando o Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------Visão Geral do Ambiente---------------------------------------\n",
      "\n",
      "Device: cpu\n",
      "Pasta de Dados:  dados\n",
      "Versões dos Pacotes Requeridos:  [('matplotlib', '3.8.0'), ('numpy', '1.26.4'), ('pandas', '2.1.4'), ('torchvision', '0.17.1'), ('tqdm', '4.65.0')]\n",
      "Dispositivo Que Será Usado Para Treinar o Modelo:  cpu\n",
      "CUDA Está Disponível?  False\n",
      "Versão do PyTorch:  2.2.1+cpu\n",
      "Versão do Lightning:  2.2.1\n",
      "\n",
      "------------------Se NVIDIA-SMI não for encontrado, então CUDA não está disponível------------------\n",
      "\n",
      "Thu Apr 18 17:42:37 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 522.06       Driver Version: 522.06       CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A    0C    P0    N/A /  N/A |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "Limpando a Memória da GPU (se disponível):  None\n",
      "\n",
      "Modelo da GPU:\n",
      "NVIDIA GeForce 940MX\n",
      "\n",
      "------------------------------------------Fim da Checagem-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Relatório completo\n",
    "\n",
    "# Verificando o dispositivo\n",
    "processing_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Verificando se GPU pode ser usada (isso depende da plataforma CUDA estar instalada)\n",
    "torch_aval = torch.cuda.is_available()\n",
    "\n",
    "# Labels para o relatório de verificação\n",
    "lable_1 = 'Visão Geral do Ambiente'\n",
    "lable_2 = 'Se NVIDIA-SMI não for encontrado, então CUDA não está disponível'\n",
    "lable_3 = 'Fim da Checagem'\n",
    "\n",
    "# Função para verificar o que está importado nesta sessão\n",
    "def get_imports():\n",
    "\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):            \n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        poorly_named_packages = {\"PIL\": \"Pillow\", \"sklearn\": \"scikit-learn\"}\n",
    "\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "\n",
    "# Imports nesta sessão\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# Loop para verificar os requerimentos\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "        \n",
    "# Pasta com os dados (quando necessário)\n",
    "pasta_dados = r'dados'\n",
    "\n",
    "print(f'{lable_1:-^100}')\n",
    "print()\n",
    "print(f\"Device:\", processing_device)\n",
    "print(f\"Pasta de Dados: \", pasta_dados)\n",
    "print(f\"Versões dos Pacotes Requeridos: \", requirements)\n",
    "print(f\"Dispositivo Que Será Usado Para Treinar o Modelo: \", processing_device)\n",
    "print(f\"CUDA Está Disponível? \", torch_aval)\n",
    "print(\"Versão do PyTorch: \", torch.__version__)\n",
    "print(\"Versão do Lightning: \", pl.__version__)\n",
    "print()\n",
    "print(f'{lable_2:-^100}\\n')\n",
    "!nvidia-smi\n",
    "gc.collect()\n",
    "print()\n",
    "print(f\"Limpando a Memória da GPU (se disponível): \", torch.cuda.empty_cache())\n",
    "print(\"\\nModelo da GPU:\")\n",
    "# Modelo da GPU usada\n",
    "!nvidia-smi --query-gpu=name --format=csv,noheader\n",
    "print(f'\\n{lable_3:-^100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento das Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos todos os caminhos das imagens e fazemos o match com as informações em HAM10000_metadata.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasta com as imagens\n",
    "pasta_imagens = 'input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém o caminho de cada imagem\n",
    "caminho_imagens = glob(os.path.join(pasta_imagens, '*', '*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um dicionário\n",
    "dict_map_imagem_caminho = {os.path.splitext(os.path.basename(x))[0]: x for x in caminho_imagens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_map_imagem_caminho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do arquivo de metadados\n",
    "df_original = pd.read_csv(os.path.join(pasta_imagens, 'HAM10000_metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona o path\n",
    "df_original['path'] = df_original['image_id'].map(dict_map_imagem_caminho.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de lesões que serão analisadas\n",
    "dict_tipo_lesao = {'nv': 'Melanocytic nevi',\n",
    "                   'mel': 'dermatofibroma',\n",
    "                   'bkl': 'Benign keratosis-like lesions ',\n",
    "                   'bcc': 'Basal cell carcinoma',\n",
    "                   'akiec': 'Actinic keratoses',\n",
    "                   'vasc': 'Vascular lesions',\n",
    "                   'df': 'Dermatofibroma'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original['cell_type'] = df_original['dx'].map(dict_tipo_lesao.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original['cell_type_idx'] = pd.Categorical(df_original['cell_type']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento\n",
    "\n",
    "Realizaremos diversas tarefas de pré-processamento das imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo Média e Desvio Padrão das Imagens\n",
    "\n",
    "Esta função é usada para calcular a média e o desvio padrão em todo o conjunto de dados e será usada para normalização das imagens de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para cálculo de média e desvio\n",
    "def calcula_img_mean_std(image_paths):\n",
    "\n",
    "    # Define altura e largura que usaremos nas imagens\n",
    "    img_h, img_w = 224, 224\n",
    "    \n",
    "    # Listas de controle\n",
    "    imgs = []\n",
    "    means, stdevs = [], []\n",
    "\n",
    "    # Loop de leitura e resize das imagens\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        imgs.append(img)\n",
    "\n",
    "    # Stack de imagens\n",
    "    imgs = np.stack(imgs, axis=3)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    # Normalização\n",
    "    imgs = imgs.astype(np.float32) / 255.\n",
    "\n",
    "    # Loop de cálculo da média e desvio\n",
    "    for i in range(3):\n",
    "        pixels = imgs[:, :, i, :].ravel()  \n",
    "        means.append(np.mean(pixels))\n",
    "        stdevs.append(np.std(pixels))\n",
    "\n",
    "    # BGR --> RGB\n",
    "    means.reverse()  \n",
    "    stdevs.reverse()\n",
    "\n",
    "    print(\"normMean = {}\".format(means))\n",
    "    print(\"normStd = {}\".format(stdevs))\n",
    "    \n",
    "    return means, stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna a média e o padrão de cada canal RGB.\n",
    "norm_mean, norm_std = calcula_img_mean_std(caminho_imagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação do Dataset de Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos verificar quantas imagens estão associadas a cada lesion_id\n",
    "df_undup = df_original.groupby('lesion_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora filtramos lesion_ids que possuem apenas uma imagem associada \n",
    "df_undup = df_undup[df_undup['image_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset do índice\n",
    "df_undup.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para identificar lesion_ids que possuem imagens duplicadas e aqueles que possuem apenas uma imagem\n",
    "def get_duplicates(x):\n",
    "    unique_list = list(df_undup['lesion_id'])\n",
    "    if x in unique_list:\n",
    "        return 'unduplicated'\n",
    "    else:\n",
    "        return 'duplicated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma nova coluna que seja uma cópia da coluna lesion_id\n",
    "df_original['duplicates'] = df_original['lesion_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função a esta nova coluna\n",
    "df_original['duplicates'] = df_original['duplicates'].apply(get_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos contar as duplicatas\n",
    "df_original['duplicates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora filtramos as imagens que não têm duplicatas\n",
    "df_undup = df_original[df_original['duplicates'] == 'unduplicated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora criamos um val set usando df_undup porque temos certeza de que nenhuma dessas imagens tem duplicatas\n",
    "y = df_undup['cell_type_idx']\n",
    "_, df_val = train_test_split(df_undup, test_size = 0.2, random_state = 101, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação das Amostras de Treino e Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função identifica se uma imagem faz parte do conjunto train ou val\n",
    "def get_val_rows(x):\n",
    "    val_list = list(df_val['image_id'])\n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica treino ou validação\n",
    "df_original['train_or_val'] = df_original['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função a esta nova coluna\n",
    "df_original['train_or_val'] = df_original['train_or_val'].apply(get_val_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra as linhas de treino\n",
    "df_treino = df_original[df_original['train_or_val'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_treino))\n",
    "print(len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que há um sério desequilíbrio de classe nos dados de treinamento. Para resolver esse problema usaremos Dataset Augmentation criando imagens sintéticas a partir das imagens originais. Leia o manual em pdf no Capítulo 7 do curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxa de dataset augmentation a ser usada em cada classe\n",
    "data_aug_rate = [15,10,5,50,0,40,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para o dataset augmentation\n",
    "for i in range(7):\n",
    "    \n",
    "    if data_aug_rate[i]:\n",
    "        \n",
    "        # Equaliza a proporção de imagens por classe nos dados de treino\n",
    "        # Geramos novas imagens multiplicando as imagens existentes pela taxa definida na lista de taxas\n",
    "        df_treino = df_treino.append([df_treino.loc[df_treino['cell_type_idx'] == i,:]] * (data_aug_rate[i] - 1), \n",
    "                                     ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset do índice\n",
    "df_treino = df_treino.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação das Amostras de Treino, Validação e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos dividir o conjunto de validação em um conjunto de validação e um conjunto de teste\n",
    "df_val, df_teste = train_test_split(df_val, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset do índice\n",
    "df_val = df_val.reset_index()\n",
    "df_teste = df_teste.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem\n",
    "\n",
    "Nesta etapa vamos constuir o processo de modelagem com 3 arquiteturas de Deep Learning. Leia os manuais em pdf no Capítulo 7 do curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Inicialização do Modelo e Definição de Arquitetura com Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extracting é um booleano que define se estamos fazendo um ajuste fino ou extração de recursos.\n",
    "# Se feature_extracting = False, o modelo é ajustado e todos os parâmetros do modelo são atualizados.\n",
    "# Se feature_extracting = True, apenas os parâmetros da última camada são atualizados, os outros permanecem fixos.\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para inicializar diferentes arquiteturas de Deep Learning\n",
    "def inicializa_modelo(model_name, num_classes, feature_extract, use_pretrained = True):\n",
    "\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    # Usaremos o modelo resnet50\n",
    "    if model_name == \"resnet\":\n",
    "        \n",
    "        # Tamanho (pixels) das imagens de entrada\n",
    "        input_size = 224\n",
    "        \n",
    "        # Carregamos o modelo pré-treinado com todos os pesos\n",
    "        model_ft = models.resnet50(pretrained = use_pretrained)\n",
    "        \n",
    "        # Treinamos o modelo e atualizamos os pesos durante o treinamento\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        \n",
    "        # Define o número de atributos de entrada\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        \n",
    "        # Camada linear final para prever a probabilidade das 7 classes com as quais estamos trabalhando\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    # Usaremos o modelo Densenet121\n",
    "    elif model_name == \"densenet\":\n",
    "        \n",
    "        # Tamanho (pixels) das imagens de entrada\n",
    "        input_size = 224\n",
    "        \n",
    "        # Carregamos o modelo pré-treinado com todos os pesos\n",
    "        model_ft = models.densenet121(pretrained = use_pretrained)\n",
    "        \n",
    "        # Treinamos o modelo e atualizamos os pesos durante o treinamento\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        \n",
    "        # Define o número de atributos de entrada\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        \n",
    "        # Camada linear final para prever a probabilidade das 7 classes com as quais estamos trabalhando\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    # Usaremos o Inception V3\n",
    "    elif model_name == \"inception\":\n",
    "        \n",
    "        # Tamanho (pixels) das imagens de entrada\n",
    "        # Tenha cuidado, pois espera-se (299 x 299) para o tamanho das imagens e ainda tem saída auxiliar\n",
    "        input_size = 299\n",
    "\n",
    "        # Carregamos o modelo pré-treinado com todos os pesos\n",
    "        model_ft = models.inception_v3(pretrained = use_pretrained)\n",
    "        \n",
    "        # Treinamos o modelo e atualizamos os pesos durante o treinamento\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        \n",
    "        # Tratando a auxilary net da arquitetura Inceptio\n",
    "        model_ft.aux_logits = False\n",
    "        \n",
    "        # Tratando a primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    else:\n",
    "        print(\"Modelo inválido...\")\n",
    "        exit()\n",
    "        \n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializando o Modelo Escolhido e Definindo Transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo que será treinado\n",
    "#nome_modelo = 'densenet'\n",
    "#nome_modelo = 'resnet'\n",
    "nome_modelo = 'inception'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos treinar o modelo e sempre atualizar os pesos\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o modelo\n",
    "model_ft, input_size = inicializa_modelo(nome_modelo, num_classes, feature_extract, use_pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o device\n",
    "device = processing_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloca o modelo no device\n",
    "model = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformações das imagens de treino\n",
    "transform_treino = transforms.Compose([transforms.Resize((input_size,input_size)),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "                                       transforms.ColorJitter(brightness = 0.1, contrast = 0.1, hue = 0.1),\n",
    "                                       transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformações das imagens de validação\n",
    "transform_val = transforms.Compose([transforms.Resize((input_size,input_size)), \n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(norm_mean, norm_std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando os DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina um organizador de dados para modelo PyTorch \n",
    "class OrganizaDados(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        X = Image.open(self.df['path'][index])\n",
    "        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organiza e transforma os dados de treino\n",
    "set_treino = OrganizaDados(df_treino, transform = transform_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o dataloader de treino\n",
    "loader_treino = DataLoader(set_treino, batch_size = 32, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O mesmo em validação\n",
    "set_val = OrganizaDados(df_val, transform = transform_val)\n",
    "loader_val = DataLoader(set_val, batch_size = 32, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O mesmo em teste\n",
    "set_teste = OrganizaDados(df_teste, transform = transform_val)\n",
    "loader_teste = DataLoader(set_teste, batch_size = 32, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos o otimizador Adam\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos cross entropy loss como função de perda\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "Nesta etapa treinaremos o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Para o Loop de Treino e Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular erro em treino e validação durante o treinamento\n",
    "class CalculaMetricas(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas para erro e acurácia em treino\n",
    "total_loss_train, total_acc_train = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de treino do modelo\n",
    "def treina_modelo(treino_loader, model, criterion, optimizer, epoch):\n",
    "    \n",
    "    # Coloca o modelo em modo de treino\n",
    "    model.train()\n",
    "    \n",
    "    # Inicializa objetos de cálculo de métricas\n",
    "    train_loss = CalculaMetricas()\n",
    "    train_acc = CalculaMetricas()\n",
    "    \n",
    "    # Iteração\n",
    "    curr_iter = (epoch - 1) * len(treino_loader)\n",
    "    \n",
    "    # Loop de treino\n",
    "    for i, data in enumerate(treino_loader):\n",
    "        \n",
    "        # Extra os dados\n",
    "        images, labels = data\n",
    "        \n",
    "        # Tamanho da imagem\n",
    "        N = images.size(0)\n",
    "        \n",
    "        # Coloca imagens e labels no device\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        # Zera os gradientes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Previsão do modelo\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Erro do modelo\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Obtem a previsão de maior probabilidade\n",
    "        prediction = outputs.max(1, keepdim = True)[1]\n",
    "        \n",
    "        # Atualiza as métricas\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        \n",
    "        # Iteração\n",
    "        curr_iter += 1\n",
    "        \n",
    "        # Print e update das métricas\n",
    "        # A condição *** and curr_iter < 1000 *** pode ser removida se você quiser treinar com o dataset completo\n",
    "        if (i + 1) % 100 == 0 and curr_iter < 1000:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (epoch, \n",
    "                                                                                       i + 1, \n",
    "                                                                                       len(treino_loader), \n",
    "                                                                                       train_loss.avg, \n",
    "                                                                                       train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "            \n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas para erro e acurácia em validação\n",
    "total_loss_val, total_acc_val = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para validação\n",
    "def valida_modelo(val_loader, model, criterion, optimizer, epoch):\n",
    "    \n",
    "    # Coloca o modelo em modo de validação\n",
    "    model.eval()\n",
    "    \n",
    "    # Inicializa objetos de cálculo de métricas\n",
    "    val_loss = CalculaMetricas()\n",
    "    val_acc = CalculaMetricas()\n",
    "    \n",
    "    # Validação\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            \n",
    "            images, labels = data\n",
    "            \n",
    "            N = images.size(0)\n",
    "            \n",
    "            images = Variable(images).to(device)\n",
    "            \n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            \n",
    "            prediction = outputs.max(1, keepdim = True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    \n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros\n",
    "epoch_num = 3\n",
    "best_val_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(1, epoch_num + 1):\n",
    "    \n",
    "    # Execute a função de treino\n",
    "    loss_train, acc_train = treina_modelo(loader_treino, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # Executa a função de validação\n",
    "    loss_val, acc_val = valida_modelo(loader_val, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # Calcula as métricas\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    \n",
    "    # Verifica a acurácia em validação\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        print('*****************************************************')\n",
    "        print('Melhor Resultado: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(num = 2)\n",
    "fig1 = fig.add_subplot(2,1,1)\n",
    "fig2 = fig.add_subplot(2,1,2)\n",
    "fig1.plot(total_loss_train, label = 'Erro em Treino')\n",
    "fig1.plot(total_acc_train, label = 'Acurácia em Treino')\n",
    "fig2.plot(total_loss_val, label = 'Erro em Validação')\n",
    "fig2.plot(total_acc_val, label = 'Acurácia em Validação')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de plot da confusion_matrix\n",
    "def plot_confusion_matrix(cm, \n",
    "                          classes,\n",
    "                          normalize = False,\n",
    "                          title = 'Confusion matrix',\n",
    "                          cmap = plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment = \"center\",\n",
    "                 color = \"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Label Real')\n",
    "    plt.xlabel('Label Previsto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo com dados de teste\n",
    "model.eval()\n",
    "y_label = []\n",
    "y_predict = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(loader_teste):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        images = Variable(images).to(device)\n",
    "        outputs = model(images)\n",
    "        prediction = outputs.max(1, keepdim = True)[1]\n",
    "        y_label.extend(labels.cpu().numpy())\n",
    "        y_predict.extend(np.squeeze(prediction.cpu().numpy().T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_label, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot da confusion matrix\n",
    "plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'nv', 'vasc','mel']\n",
    "plot_confusion_matrix(confusion_mtx, plot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera o relatório de classificação\n",
    "report = classification_report(y_label, y_predict, target_names = plot_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de erros por classe\n",
    "label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis = 1)\n",
    "plt.bar(np.arange(7),label_frac_error)\n",
    "plt.xlabel('Label Real')\n",
    "plt.ylabel('Classificação Incorreta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conseguimos 0.87574 de acurácia com o modelo DenseNet.\n",
    "- Conseguimos 0.86607 de acurácia com o modelo ResNet.\n",
    "- Conseguimos 0.86533 de acurácia com o modelo Inception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
